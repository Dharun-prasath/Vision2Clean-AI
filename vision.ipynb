{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c206c9c6",
   "metadata": {},
   "source": [
    "### Vision2Clean AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b2fd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Install dependencies with CUDA-enabled PyTorch\n",
    "# Run this once to set up your environment with CUDA support\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --quiet\n",
    "%pip install ultralytics opencv-python matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1bd2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ GPU & Environment Check\n",
      "============================================================\n",
      "‚úÖ PyTorch version: 2.5.1+cu121\n",
      "‚úÖ CUDA available: True\n",
      "‚úÖ CUDA version: 12.1\n",
      "‚úÖ cuDNN version: 90100\n",
      "‚úÖ GPU count: 1\n",
      "   ‚îî‚îÄ GPU 0: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "‚úÖ Current device: cuda:0\n",
      "\n",
      "üéØ Selected device: cuda\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 2Ô∏è‚É£ Import libraries and check CUDA GPU\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üöÄ GPU & Environment Check\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"‚úÖ cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"‚úÖ GPU count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"   ‚îî‚îÄ GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"‚úÖ Current device: cuda:{torch.cuda.current_device()}\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  CUDA not available - will use CPU\")\n",
    "    print(\"   Run cell 1 to install CUDA-enabled PyTorch\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"\\nüéØ Selected device: {device}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38f3edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: train/images\n",
      "val: valid/images\n",
      "test: test/images\n",
      "\n",
      "nc: 5\n",
      "names: ['Cardboard', 'Glass', 'Metal', 'Paper', 'Plastic']\n",
      "\n",
      "roboflow:\n",
      "  workspace: waste-segmentation-vlidl\n",
      "  project: poster-dataset-ctglo\n",
      "  version: 2\n",
      "  license: CC BY 4.0\n",
      "  url: https://universe.roboflow.com/waste-segmentation-vlidl/poster-dataset-ctglo/dataset/2\n"
     ]
    }
   ],
   "source": [
    "# 3Ô∏è‚É£ Define dataset YAML path\n",
    "data_yaml = r\"D:\\Documents\\Portfolio.github\\Vision2Clean-AI\\Dataset\\data.yaml\"\n",
    "\n",
    "# Check YAML file\n",
    "!type \"{data_yaml}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b958ebf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ Load pretrained YOLOv11 segmentation model\n",
    "model = YOLO(\"yolo11n-seg.pt\")\n",
    "\n",
    "# 5Ô∏è‚É£ Choose device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"     # Apple Silicon GPU\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"    # NVIDIA GPU\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"üöÄ Training on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf5070",
   "metadata": {},
   "source": [
    "---\n",
    "## üéì Training with Checkpoints\n",
    "\n",
    "**Good news!** YOLO automatically saves your progress:\n",
    "\n",
    "‚úÖ **Automatic saves:**\n",
    "- `last.pt` - Latest checkpoint (for resuming)\n",
    "- `best.pt` - Best model based on validation accuracy\n",
    "- Saved every 5 epochs + at the end\n",
    "\n",
    "‚úÖ **You can safely stop training:**\n",
    "- Press **Interrupt** button or `Ctrl+C`\n",
    "- All progress up to the last checkpoint is saved\n",
    "- Resume anytime using Cell 6b\n",
    "\n",
    "‚úÖ **Checkpoint location:**\n",
    "```\n",
    "runs/segment/vision2clean_yolo11_seg/weights/\n",
    "```\n",
    "\n",
    "üí° **Pro tip:** If training is too slow, reduce `batch` size or `epochs` in Cell 6.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6cf25d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 6Ô∏è‚É£ Start fine-tuning with automatic checkpoint saving\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# YOLO automatically saves checkpoints:\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#   - last.pt: Latest checkpoint (can resume from here)\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#   - best.pt: Best model based on validation metrics\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# You can stop training anytime (Ctrl+C) and resume later!\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müéØ Starting training on device:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mdevice\u001b[49m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìÅ Checkpoints will be saved to: runs/segment/vision2clean_yolo11_seg/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müíæ Auto-saves: last.pt (resume) & best.pt (best model)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "# 6Ô∏è‚É£ Start fine-tuning with automatic checkpoint saving\n",
    "# YOLO automatically saves checkpoints:\n",
    "#   - last.pt: Latest checkpoint (can resume from here)\n",
    "#   - best.pt: Best model based on validation metrics\n",
    "# You can stop training anytime (Ctrl+C) and resume later!\n",
    "\n",
    "print(\"üéØ Starting training on device:\", device)\n",
    "print(\"üìÅ Checkpoints will be saved to: runs/segment/vision2clean_yolo11_seg/\")\n",
    "print(\"üíæ Auto-saves: last.pt (resume) & best.pt (best model)\")\n",
    "print(\"‚è∏Ô∏è  Stop anytime with Ctrl+C - progress is saved!\\n\")\n",
    "\n",
    "model.train(\n",
    "    data=data_yaml,          # Path to dataset YAML\n",
    "    epochs=100,              # Total epochs\n",
    "    imgsz=640,               # Input image size\n",
    "    batch=8,                 # Reduce if RAM/GPU limited (try 16 if you have VRAM)\n",
    "    device=device,           # CUDA / CPU\n",
    "    project=\"runs/segment\",\n",
    "    name=\"vision2clean_yolo11_seg\",\n",
    "    \n",
    "    # Checkpoint settings\n",
    "    save=True,               # Save checkpoints\n",
    "    save_period=5,           # Save checkpoint every 5 epochs (adjust as needed)\n",
    "    \n",
    "    # Performance optimizations for GPU\n",
    "    cache=True,              # Cache images for faster training\n",
    "    workers=4,               # Number of dataloader workers\n",
    "    amp=True,                # Automatic Mixed Precision (faster on GPU)\n",
    "    \n",
    "    # Monitoring\n",
    "    plots=True,              # Save training plots\n",
    "    verbose=True             # Show detailed progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No checkpoint found at: runs/segment/vision2clean_yolo11_seg/weights/last.pt\n",
      "   Run cell 6 first to start training from scratch\n"
     ]
    }
   ],
   "source": [
    "# 6Ô∏è‚É£b (OPTIONAL) Resume training from last checkpoint\n",
    "# Run this cell ONLY if training was interrupted and you want to continue\n",
    "# It will load the last checkpoint and continue from where it stopped\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Re-detect device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"üéØ Device: {device}\")\n",
    "\n",
    "checkpoint_path = \"runs/segment/vision2clean_yolo11_seg/weights/last.pt\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"‚úÖ Found checkpoint: {checkpoint_path}\")\n",
    "    print(\"üîÑ Resuming training from last saved state...\\n\")\n",
    "    \n",
    "    # Load model from checkpoint\n",
    "    model = YOLO(checkpoint_path)\n",
    "    \n",
    "    # Resume training (it will continue from the last epoch)\n",
    "    model.train(\n",
    "        resume=True,              # Resume from checkpoint\n",
    "        device=device\n",
    "    )\n",
    "else:\n",
    "    print(f\"‚ùå No checkpoint found at: {checkpoint_path}\")\n",
    "    print(\"   Run cell 6 first to start training from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f78089",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 7Ô∏è‚É£ Evaluate model on validation set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m metrics = \u001b[43mmodel\u001b[49m.val()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Evaluation Results:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 7Ô∏è‚É£ Evaluate model on validation set\n",
    "# Run this after training completes to see final metrics\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Re-detect device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# Load the best trained model\n",
    "model = YOLO(\"runs/segment/vision2clean_yolo11_seg/weights/best.pt\")\n",
    "\n",
    "print(f\"üéØ Evaluating on device: {device}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run validation\n",
    "metrics = model.val(device=device)\n",
    "\n",
    "print(\"\\n‚úÖ Evaluation Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe785021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8Ô∏è‚É£ Test on sample image\n",
    "\n",
    "\n",
    "# 9Ô∏è‚É£ (Optional) Test live webcam\n",
    "#results = model.predict(source=0, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c6312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üöÄ Vision2Clean AI ‚Äî Test Fine-Tuned YOLOv11-Seg with Webcam\n",
    "# =============================================================\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1Ô∏è‚É£ Load your fine-tuned model\n",
    "model = YOLO(\"runs/segment/vision2clean_yolo11_seg/weights/best.pt\")\n",
    "\n",
    "# 2Ô∏è‚É£ Choose the best device automatically\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"      # Apple Silicon GPU\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"     # NVIDIA GPU\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# 3Ô∏è‚É£ Open laptop webcam (0 = default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Error: Could not access webcam.\")\n",
    "    raise SystemExit()\n",
    "\n",
    "# 4Ô∏è‚É£ Live detection loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLOv11-Seg inference\n",
    "    results = model(frame, device=device, verbose=False)[0]\n",
    "\n",
    "    # Draw masks + labels on the frame\n",
    "    annotated = results.plot()\n",
    "\n",
    "    # Display in window\n",
    "    cv2.imshow(\"Vision2Clean AI ‚Äî Live Waste Detection\", annotated)\n",
    "\n",
    "    # Exit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 5Ô∏è‚É£ Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"üëã Stream closed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
